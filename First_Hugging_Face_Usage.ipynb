{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["Installing Transformers"],"metadata":{"id":"OKI4HZwo2rPR"}},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UeX_za3d2dZ5","executionInfo":{"status":"ok","timestamp":1667749265027,"user_tz":-60,"elapsed":26628,"user":{"displayName":"Fares Soltani","userId":"10112081647688905068"}},"outputId":"377a6e37-d4a3-41da-da40-25a63a738093"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.24.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.13.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.13.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.1)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.1.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.10.0)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.9.24)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.12.1+cu113)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (4.1.1)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (0.1.97)\n"]}],"source":["!pip install transformers\n","!pip install torch\n","!pip install sentencepiece # for huggingface model"]},{"cell_type":"markdown","source":["Necessary Imports"],"metadata":{"id":"OZehgn8Q2vac"}},{"cell_type":"code","source":["from transformers import AutoTokenizer, TFAutoModelForSequenceClassification #TF for Tensorflow\n","from transformers import pipeline\n","import torch\n","import torch.nn.functional as F"],"metadata":{"id":"iJMWSIPc2pqH","executionInfo":{"status":"ok","timestamp":1667749283015,"user_tz":-60,"elapsed":17992,"user":{"displayName":"Fares Soltani","userId":"10112081647688905068"}}},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":["### **First time using Hugging Face !** : Sentiment Analysis of French text using tf-allociné model (A french sentiment analysis model, based on CamemBERT, and finetuned on a large-scale dataset scraped from Allociné.fr user reviews)"],"metadata":{"id":"J_G8O4Fz3LlX"}},{"cell_type":"markdown","source":["Load classifier"],"metadata":{"id":"E7zsHwxb3tsu"}},{"cell_type":"code","source":["tokenizer = AutoTokenizer.from_pretrained(\"tblard/tf-allocine\")\n","model = TFAutoModelForSequenceClassification.from_pretrained(\"tblard/tf-allocine\")\n","\n","classifier = pipeline('sentiment-analysis', model=model, tokenizer=tokenizer)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"q5Bej-X_3K6i","executionInfo":{"status":"ok","timestamp":1667749292902,"user_tz":-60,"elapsed":9890,"user":{"displayName":"Fares Soltani","userId":"10112081647688905068"}},"outputId":"16ebbc79-4cfe-4e92-dfa5-be2b1b913b49"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stderr","text":["All model checkpoint layers were used when initializing TFCamembertForSequenceClassification.\n","\n","All the layers of TFCamembertForSequenceClassification were initialized from the model checkpoint at tblard/tf-allocine.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFCamembertForSequenceClassification for predictions without further training.\n"]}]},{"cell_type":"markdown","source":["Perform sentiment analysis on different texts"],"metadata":{"id":"Pi3MYfsj3zG1"}},{"cell_type":"code","source":["positive_text = \"Aujourd'hui je me sens super! Je vais sortir avec mes potes\"\n","classifier(positive_text)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Jpo1opXq3cdK","executionInfo":{"status":"ok","timestamp":1667749293966,"user_tz":-60,"elapsed":1075,"user":{"displayName":"Fares Soltani","userId":"10112081647688905068"}},"outputId":"ba337118-8a3c-4d12-a609-c435b6990edd"},"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[{'label': 'POSITIVE', 'score': 0.9643841981887817}]"]},"metadata":{},"execution_count":4}]},{"cell_type":"code","source":["neutral_text = \"J'ai regardé le concert d'Ed Sheeran la semaine dernière\"\n","classifier(neutral_text)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cdX5tQdF3haM","executionInfo":{"status":"ok","timestamp":1667749294781,"user_tz":-60,"elapsed":817,"user":{"displayName":"Fares Soltani","userId":"10112081647688905068"}},"outputId":"04452805-9166-42d9-c9d6-13775ff71104"},"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[{'label': 'POSITIVE', 'score': 0.5830837488174438}]"]},"metadata":{},"execution_count":5}]},{"cell_type":"code","source":["negative_text = \"Les services de transport ici sont génants\"\n","classifier(negative_text)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TQ6uktXA8RFj","executionInfo":{"status":"ok","timestamp":1667749295773,"user_tz":-60,"elapsed":994,"user":{"displayName":"Fares Soltani","userId":"10112081647688905068"}},"outputId":"f36811b0-dc81-42e9-fc6f-33c245eb3e47"},"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[{'label': 'NEGATIVE', 'score': 0.6865605115890503}]"]},"metadata":{},"execution_count":6}]},{"cell_type":"code","source":["texts_list = [\"Aujourd'hui je me sens super! Je vais sortir avec mes potes\", \"J'ai regardé le concert d'Ed Sheeran la semaine dernière\", \"Les services de transport ici sont génants\"]\n","classifier(texts_list)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yMWa1Znq8iSo","executionInfo":{"status":"ok","timestamp":1667749298331,"user_tz":-60,"elapsed":2560,"user":{"displayName":"Fares Soltani","userId":"10112081647688905068"}},"outputId":"5ff87306-1bf7-4fa1-ab10-903759c6fb3e"},"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[{'label': 'POSITIVE', 'score': 0.9643841981887817},\n"," {'label': 'POSITIVE', 'score': 0.5830837488174438},\n"," {'label': 'NEGATIVE', 'score': 0.6865605115890503}]"]},"metadata":{},"execution_count":7}]},{"cell_type":"markdown","source":["### Fine tuning"],"metadata":{"id":"NRCln7ydOaRw"}},{"cell_type":"markdown","source":["Importing necessary libraries"],"metadata":{"id":"MZVGWzuIO7tN"}},{"cell_type":"code","source":["from pathlib import Path\n","from torch.utils.data import Dataset\n","from sklearn.model_selection import train_test_split\n","from transformers import DistilBertTokenizerFast, DistilBertForSequenceClassification\n","from transformers import Trainer, TrainingArguments"],"metadata":{"id":"bE8z0Ds7O-v_","executionInfo":{"status":"ok","timestamp":1667749298332,"user_tz":-60,"elapsed":5,"user":{"displayName":"Fares Soltani","userId":"10112081647688905068"}}},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":["Prepare Dataset"],"metadata":{"id":"REfmxlhNOjjw"}},{"cell_type":"code","source":["# Read dataset and adapt it to our usage\n","def read_imdb_dataset(dataset_dir):\n","  dataset_dir = Path(dataset_dir)\n","  texts = []\n","  labels = []\n","  for label in [\"pos\", \"neg\"]:\n","    for text_file in (dataset_dir/label).iterdir():\n","      texts.append(text_file.read_text())\n","      labels.append(0 if label == \"neg\" else 1)\n","  return texts, labels"],"metadata":{"id":"wlwvwz2a8tfk","executionInfo":{"status":"ok","timestamp":1667749298332,"user_tz":-60,"elapsed":4,"user":{"displayName":"Fares Soltani","userId":"10112081647688905068"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["# Mount drive files\n","\n","from google.colab import drive\n","\n","drive.mount('/content/gdrive/', force_remount=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7jsfPec5PswQ","executionInfo":{"status":"ok","timestamp":1667749303163,"user_tz":-60,"elapsed":4835,"user":{"displayName":"Fares Soltani","userId":"10112081647688905068"}},"outputId":"ac4a9b0d-a640-4a54-b58a-5da64e669b7c"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive/\n"]}]},{"cell_type":"code","source":["# Uncompress dataset file we got from https://ai.stanford.edu/~amaas/data/sentiment/\n","import tarfile\n","\n","file = tarfile.open('/content/gdrive/MyDrive/aclImdb_v1.tar.gz')\n","file.extractall('./aclImdb')\n","file.close()"],"metadata":{"id":"kQ1SSzfxao5S","executionInfo":{"status":"ok","timestamp":1667749350475,"user_tz":-60,"elapsed":47314,"user":{"displayName":"Fares Soltani","userId":"10112081647688905068"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["# get data\n","\n","train_texts, train_labels = read_imdb_dataset('./aclImdb/aclImdb/train')\n","test_texts, test_labels = read_imdb_dataset('./aclImdb/aclImdb/test')"],"metadata":{"id":"QDmHW40mbk_N","executionInfo":{"status":"ok","timestamp":1667749352447,"user_tz":-60,"elapsed":1975,"user":{"displayName":"Fares Soltani","userId":"10112081647688905068"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["# Shuffle training data and create validation dataset\n","\n","train_texts, val_texts, train_labels, val_labels = train_test_split(train_texts, train_labels, test_size=.2)"],"metadata":{"id":"sVTr0tHNc2IT","executionInfo":{"status":"ok","timestamp":1667749352447,"user_tz":-60,"elapsed":3,"user":{"displayName":"Fares Soltani","userId":"10112081647688905068"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["# Create an IMDB Dataset class, I saw this in a tutorial recently and it is very useful\n","\n","class IMDbDataset(Dataset):\n","  def __init__(self, encodings, labels):\n","    self.encodings = encodings\n","    self.labels = labels\n","\n","  def __getitem__(self, id):\n","    item = {key: torch.tensor(val[id]) for key, val in self.encodings.items()}\n","    item['label'] = torch.tensor(self.labels[id])\n","    return item\n","\n","  def __len__(self):\n","    return len(self.labels)\n"],"metadata":{"id":"Q3MAXevfdZBg","executionInfo":{"status":"ok","timestamp":1667749352448,"user_tz":-60,"elapsed":4,"user":{"displayName":"Fares Soltani","userId":"10112081647688905068"}}},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":["Import the tokenizer:"],"metadata":{"id":"jKuam-2vhy2B"}},{"cell_type":"code","source":["model_name = 'distilbert-base-uncased'\n","tokenizer = DistilBertTokenizerFast.from_pretrained(model_name)"],"metadata":{"id":"_eaDzZk8h1eE","executionInfo":{"status":"ok","timestamp":1667749352873,"user_tz":-60,"elapsed":429,"user":{"displayName":"Fares Soltani","userId":"10112081647688905068"}}},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":["Tokenize our text"],"metadata":{"id":"DUKC6gkOiTR7"}},{"cell_type":"code","source":["train_encodings = tokenizer(train_texts, truncation=True, padding=True)\n","val_encodings = tokenizer(val_texts, truncation=True, padding=True)\n","test_encodings = tokenizer(test_texts, truncation=True, padding=True)"],"metadata":{"id":"7GFgnNH-iVYS","executionInfo":{"status":"ok","timestamp":1667749393344,"user_tz":-60,"elapsed":40473,"user":{"displayName":"Fares Soltani","userId":"10112081647688905068"}}},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":["Create our Dataset objects so we can"],"metadata":{"id":"CburiDMti8Z8"}},{"cell_type":"code","source":["train_dataset = IMDbDataset(train_encodings, train_labels)\n","val_dataset = IMDbDataset(val_encodings, val_labels)\n","test_dataset = IMDbDataset(test_encodings, test_labels)"],"metadata":{"id":"VSqvJStEjXKb","executionInfo":{"status":"ok","timestamp":1667749393345,"user_tz":-60,"elapsed":15,"user":{"displayName":"Fares Soltani","userId":"10112081647688905068"}}},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":["Setup Training arguments"],"metadata":{"id":"Ag1YNMbQjvDu"}},{"cell_type":"code","source":["training_args = TrainingArguments(\n","    output_dir='./results',\n","    num_train_epochs=2,\n","    per_device_train_batch_size=16,\n","    per_device_eval_batch_size=64,\n","    warmup_steps=500,\n","    learning_rate=5e-5,\n","    weight_decay=0.01,\n","    logging_dir='./logs',\n","    logging_steps=10,\n","    optim='adamw_torch'\n",")"],"metadata":{"id":"_Lvg5ZzMjt3F","executionInfo":{"status":"ok","timestamp":1667749393345,"user_tz":-60,"elapsed":14,"user":{"displayName":"Fares Soltani","userId":"10112081647688905068"}}},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":["Initialize model and trainer, then train the pre-trained model to fine-tune it to our case"],"metadata":{"id":"Qruw-up5kr_O"}},{"cell_type":"code","source":["# initializing the model (from pre-trained model)\n","model = DistilBertForSequenceClassification.from_pretrained(model_name)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WFuiaFa8krFF","executionInfo":{"status":"ok","timestamp":1667749396051,"user_tz":-60,"elapsed":2719,"user":{"displayName":"Fares Soltani","userId":"10112081647688905068"}},"outputId":"768133b8-b5b8-45a5-f0af-888eb52c8539"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.weight', 'vocab_projector.weight', 'vocab_transform.bias', 'vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.bias']\n","- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}]},{"cell_type":"code","source":["# Initializing trainer\n","\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=train_dataset,\n","    eval_dataset=val_dataset\n",")"],"metadata":{"id":"3KXxBoNKk8qr","executionInfo":{"status":"ok","timestamp":1667749396052,"user_tz":-60,"elapsed":5,"user":{"displayName":"Fares Soltani","userId":"10112081647688905068"}}},"execution_count":20,"outputs":[]},{"cell_type":"code","source":["# Train !\n","\n","trainer.train()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":214},"id":"JTXC-5OTlMDz","outputId":"fb1e9dab-7e1d-4402-c251-5b8d43064705"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["***** Running training *****\n","  Num examples = 20000\n","  Num Epochs = 2\n","  Instantaneous batch size per device = 16\n","  Total train batch size (w. parallel, distributed & accumulation) = 16\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 2500\n","  Number of trainable parameters = 66955010\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='2' max='2500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [   2/2500 : < :, Epoch 0.00/2]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","  </tbody>\n","</table><p>"]},"metadata":{}}]},{"cell_type":"code","source":[],"metadata":{"id":"yr1zQ_ZylO36"},"execution_count":null,"outputs":[]}]}